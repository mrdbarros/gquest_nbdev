{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up and Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This kernel uses fastai and Huggingface transformser. fastai is already installed on Kaggle, and [here](https://www.kaggle.com/c/tensorflow2-question-answering/discussion/117716) is a discussion post that shows how to get Huggingface installled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This statement prints all of the directories in the /kaggle/input/ directory. This can be useful when trying to determine the path of the external datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from gquest_nbdev.fastai_huggingface import * \n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import pdb\n",
    "from pathlib import Path \n",
    "from fastai.text import *\n",
    "from fastai.tabular import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "/kaggle/input\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    print(dirname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A utility function to set the seed for generating random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "seed=42\n",
    "seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#os.chdir(Path(\"./gquest_nbdev\"))\n",
    "#os.chdir(Path(\"/home/mrdbarros/projetos/gquest_nbdev\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "(6079, 41) (476, 11)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "model_type = 'roberta'\n",
    "pretrained_model_name = 'roberta-base' # 'roberta-base-openai-detector'\n",
    "DATA_ROOT = Path(\"../input/google-quest-challenge/\")\n",
    "MODEL_ROOT = Path(\"../input/\"+pretrained_model_name)\n",
    "train = pd.read_csv(DATA_ROOT / 'train.csv')\n",
    "test = pd.read_csv(DATA_ROOT / 'test.csv')\n",
    "sample_sub = pd.read_csv(DATA_ROOT / 'sample_submission.csv')\n",
    "print(train.shape,test.shape)\n",
    "download_model=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data. In this kernel, I'll use the `question_title`, `question_body` and `answer` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   qa_id                                     question_title  \\\n0      0  What am I losing when using extension tubes in...   \n1      1  What is the distinction between a city and a s...   \n2      2  Maximum protusion length for through-hole comp...   \n3      3              Can an affidavit be used in Beit Din?   \n4      5       How do you make a binary image in Photoshop?   \n\n                                       question_body question_user_name  \\\n0  After playing around with macro photography on...               ysap   \n1  I am trying to understand what kinds of places...      russellpierce   \n2  I'm working on a PCB that has through-hole com...          Joe Baker   \n3  An affidavit, from what i understand, is basic...         Scimonster   \n4  I am trying to make a binary image. I want mor...            leigero   \n\n                                  question_user_page  \\\n0         https://photo.stackexchange.com/users/1024   \n1           https://rpg.stackexchange.com/users/8774   \n2  https://electronics.stackexchange.com/users/10157   \n3       https://judaism.stackexchange.com/users/5151   \n4  https://graphicdesign.stackexchange.com/users/...   \n\n                                              answer answer_user_name  \\\n0  I just got extension tubes, so here's the skin...           rfusca   \n1  It might be helpful to look into the definitio...     Erik Schmidt   \n2  Do you even need grooves?  We make several pro...      Dwayne Reid   \n3  Sending an \"affidavit\" it is a dispute between...    Y     e     z   \n4  Check out Image Trace in Adobe Illustrator. \\n...             q2ra   \n\n                                    answer_user_page  \\\n0         https://photo.stackexchange.com/users/1917   \n1           https://rpg.stackexchange.com/users/1871   \n2  https://electronics.stackexchange.com/users/64754   \n3       https://judaism.stackexchange.com/users/4794   \n4  https://graphicdesign.stackexchange.com/users/...   \n\n                                                 url   category  ...  \\\n0  http://photo.stackexchange.com/questions/9169/...  LIFE_ARTS  ...   \n1  http://rpg.stackexchange.com/questions/47820/w...    CULTURE  ...   \n2  http://electronics.stackexchange.com/questions...    SCIENCE  ...   \n3  http://judaism.stackexchange.com/questions/551...    CULTURE  ...   \n4  http://graphicdesign.stackexchange.com/questio...  LIFE_ARTS  ...   \n\n  question_well_written  answer_helpful  answer_level_of_information  \\\n0              1.000000        1.000000                     0.666667   \n1              0.888889        0.888889                     0.555556   \n2              0.777778        0.777778                     0.555556   \n3              0.888889        0.833333                     0.333333   \n4              1.000000        1.000000                     0.666667   \n\n   answer_plausible  answer_relevance  answer_satisfaction  \\\n0          1.000000          1.000000             0.800000   \n1          0.888889          0.888889             0.666667   \n2          1.000000          1.000000             0.666667   \n3          0.833333          1.000000             0.800000   \n4          1.000000          1.000000             0.800000   \n\n   answer_type_instructions  answer_type_procedure  \\\n0                       1.0               0.000000   \n1                       0.0               0.000000   \n2                       0.0               0.333333   \n3                       0.0               0.000000   \n4                       1.0               0.000000   \n\n   answer_type_reason_explanation  answer_well_written  \n0                        0.000000             1.000000  \n1                        0.666667             0.888889  \n2                        1.000000             0.888889  \n3                        1.000000             1.000000  \n4                        1.000000             1.000000  \n\n[5 rows x 41 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>qa_id</th>\n      <th>question_title</th>\n      <th>question_body</th>\n      <th>question_user_name</th>\n      <th>question_user_page</th>\n      <th>answer</th>\n      <th>answer_user_name</th>\n      <th>answer_user_page</th>\n      <th>url</th>\n      <th>category</th>\n      <th>...</th>\n      <th>question_well_written</th>\n      <th>answer_helpful</th>\n      <th>answer_level_of_information</th>\n      <th>answer_plausible</th>\n      <th>answer_relevance</th>\n      <th>answer_satisfaction</th>\n      <th>answer_type_instructions</th>\n      <th>answer_type_procedure</th>\n      <th>answer_type_reason_explanation</th>\n      <th>answer_well_written</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>What am I losing when using extension tubes in...</td>\n      <td>After playing around with macro photography on...</td>\n      <td>ysap</td>\n      <td>https://photo.stackexchange.com/users/1024</td>\n      <td>I just got extension tubes, so here's the skin...</td>\n      <td>rfusca</td>\n      <td>https://photo.stackexchange.com/users/1917</td>\n      <td>http://photo.stackexchange.com/questions/9169/...</td>\n      <td>LIFE_ARTS</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.666667</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.800000</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>What is the distinction between a city and a s...</td>\n      <td>I am trying to understand what kinds of places...</td>\n      <td>russellpierce</td>\n      <td>https://rpg.stackexchange.com/users/8774</td>\n      <td>It might be helpful to look into the definitio...</td>\n      <td>Erik Schmidt</td>\n      <td>https://rpg.stackexchange.com/users/1871</td>\n      <td>http://rpg.stackexchange.com/questions/47820/w...</td>\n      <td>CULTURE</td>\n      <td>...</td>\n      <td>0.888889</td>\n      <td>0.888889</td>\n      <td>0.555556</td>\n      <td>0.888889</td>\n      <td>0.888889</td>\n      <td>0.666667</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.666667</td>\n      <td>0.888889</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Maximum protusion length for through-hole comp...</td>\n      <td>I'm working on a PCB that has through-hole com...</td>\n      <td>Joe Baker</td>\n      <td>https://electronics.stackexchange.com/users/10157</td>\n      <td>Do you even need grooves?  We make several pro...</td>\n      <td>Dwayne Reid</td>\n      <td>https://electronics.stackexchange.com/users/64754</td>\n      <td>http://electronics.stackexchange.com/questions...</td>\n      <td>SCIENCE</td>\n      <td>...</td>\n      <td>0.777778</td>\n      <td>0.777778</td>\n      <td>0.555556</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.666667</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>1.000000</td>\n      <td>0.888889</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Can an affidavit be used in Beit Din?</td>\n      <td>An affidavit, from what i understand, is basic...</td>\n      <td>Scimonster</td>\n      <td>https://judaism.stackexchange.com/users/5151</td>\n      <td>Sending an \"affidavit\" it is a dispute between...</td>\n      <td>Y     e     z</td>\n      <td>https://judaism.stackexchange.com/users/4794</td>\n      <td>http://judaism.stackexchange.com/questions/551...</td>\n      <td>CULTURE</td>\n      <td>...</td>\n      <td>0.888889</td>\n      <td>0.833333</td>\n      <td>0.333333</td>\n      <td>0.833333</td>\n      <td>1.000000</td>\n      <td>0.800000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>How do you make a binary image in Photoshop?</td>\n      <td>I am trying to make a binary image. I want mor...</td>\n      <td>leigero</td>\n      <td>https://graphicdesign.stackexchange.com/users/...</td>\n      <td>Check out Image Trace in Adobe Illustrator. \\n...</td>\n      <td>q2ra</td>\n      <td>https://graphicdesign.stackexchange.com/users/...</td>\n      <td>http://graphicdesign.stackexchange.com/questio...</td>\n      <td>LIFE_ARTS</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.666667</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.800000</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 41 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 7
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted lables are in the columns of the sample submission. Note that some labels are with respect to the question, and some are with respect to the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "labels = list(sample_sub.columns[1:].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "question_asker_intent_understanding\n",
      "question_body_critical\n",
      "question_conversational\n",
      "question_expect_short_answer\n",
      "question_fact_seeking\n",
      "question_has_commonly_accepted_answer\n",
      "question_interestingness_others\n",
      "question_interestingness_self\n",
      "question_multi_intent\n",
      "question_not_really_a_question\n",
      "question_opinion_seeking\n",
      "question_type_choice\n",
      "question_type_compare\n",
      "question_type_consequence\n",
      "question_type_definition\n",
      "question_type_entity\n",
      "question_type_instructions\n",
      "question_type_procedure\n",
      "question_type_reason_explanation\n",
      "question_type_spelling\n",
      "question_well_written\n",
      "answer_helpful\n",
      "answer_level_of_information\n",
      "answer_plausible\n",
      "answer_relevance\n",
      "answer_satisfaction\n",
      "answer_type_instructions\n",
      "answer_type_procedure\n",
      "answer_type_reason_explanation\n",
      "answer_well_written\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "for label in labels: print(label) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "train[['question_title','question_body','answer']].to_csv(Path('../input/raw_text.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "seed = 42\n",
    "use_fp16 = True\n",
    "bs = 8\n",
    "MAX_SEQUENCE_LENGTH = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "model_class, tokenizer_class, config_class = MODEL_CLASSES[model_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "mkdir: cannot create directory ‘../input/roberta-base’: File exists\r\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "if download_model:\n",
    "    new_dir=Path(\"../input\")/pretrained_model_name\n",
    "    !mkdir {new_dir}\n",
    "    transformer_tokenizer = tokenizer_class.from_pretrained(pretrained_model_name)\n",
    "    transformer_tokenizer.save_pretrained(MODEL_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['roberta-base', 'roberta-large', 'roberta-large-mnli', 'distilroberta-base', 'roberta-base-openai-detector', 'roberta-large-openai-detector'])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 14
    }
   ],
   "source": [
    "model_class.pretrained_model_archive_map.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train['question_title_body']=train['question_title'] +\" \" + train['question_body']\n",
    "test['question_title_body']=test['question_title'] +\" \" + test['question_body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "if download_model:\n",
    "    transformer_tokenizer = tokenizer_class.from_pretrained(pretrained_model_name)\n",
    "    transformer_tokenizer.save_pretrained(MODEL_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "transformer_tokenizer = tokenizer_class.from_pretrained(MODEL_ROOT)\n",
    "transformer_base_tokenizer = TransformersBaseTokenizer(pretrained_tokenizer = transformer_tokenizer, model_type = model_type)\n",
    "fastai_tokenizer = Tokenizer_MultiColumn(tok_func = transformer_base_tokenizer, pre_rules=[], post_rules=[],n_cpus=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "transformer_vocab =  TransformersVocab(tokenizer = transformer_tokenizer)\n",
    "numericalize_processor = NumericalizeProcessor(vocab=transformer_vocab)\n",
    "\n",
    "tokenize_processor = TokenizeProcessorDualBert(tokenizer=fastai_tokenizer, include_bos=False, include_eos=False)\n",
    "\n",
    "transformer_processor = [tokenize_processor, numericalize_processor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "pad_first = bool(model_type in ['xlnet'])\n",
    "pad_idx = transformer_tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[array([0.333333, 0.444444, 0.5     , 0.555556, 0.666667, 0.777778, 0.833333, 0.888889, 1.      ]),\n array([0.333333, 0.444444, 0.5     , 0.555556, 0.666667, 0.777778, 0.833333, 0.888889, 1.      ]),\n array([0.      , 0.333333, 0.5     , 0.666667, 1.      ]),\n array([0.      , 0.333333, 0.5     , 0.666667, 1.      ]),\n array([0.      , 0.333333, 0.5     , 0.666667, 1.      ]),\n array([0.      , 0.333333, 0.5     , 0.666667, 1.      ]),\n array([0.333333, 0.444444, 0.5     , 0.555556, 0.666667, 0.777778, 0.833333, 0.888889, 1.      ]),\n array([0.333333, 0.444444, 0.5     , 0.555556, 0.666667, 0.777778, 0.833333, 0.888889, 1.      ]),\n array([0.      , 0.333333, 0.5     , 0.666667, 1.      ]),\n array([0.      , 0.333333, 0.5     , 0.666667, 1.      ]),\n array([0.      , 0.333333, 0.5     , 0.666667, 1.      ]),\n array([0.      , 0.333333, 0.5     , 0.666667, 1.      ]),\n array([0.      , 0.333333, 0.5     , 0.666667, 1.      ]),\n array([0.      , 0.333333, 0.5     , 0.666667, 1.      ]),\n array([0.      , 0.333333, 0.5     , 0.666667, 1.      ]),\n array([0.      , 0.333333, 0.5     , 0.666667, 1.      ]),\n array([0.      , 0.333333, 0.5     , 0.666667, 1.      ]),\n array([0.      , 0.333333, 0.5     , 0.666667, 1.      ]),\n array([0.      , 0.333333, 0.5     , 0.666667, 1.      ]),\n array([0.      , 0.333333, 0.666667]),\n array([0.333333, 0.444444, 0.5     , 0.555556, 0.666667, 0.777778, 0.833333, 0.888889, 1.      ]),\n array([0.333333, 0.444444, 0.5     , 0.555556, 0.666667, 0.777778, 0.833333, 0.888889, 1.      ]),\n array([0.333333, 0.444444, 0.5     , 0.555556, 0.666667, 0.777778, 0.833333, 0.888889, 1.      ]),\n array([0.333333, 0.444444, 0.5     , 0.555556, 0.666667, 0.777778, 0.833333, 0.888889, 1.      ]),\n array([0.333333, 0.444444, 0.5     , 0.555556, 0.666667, 0.777778, 0.833333, 0.888889, 1.      ]),\n array([0.2     , 0.266667, 0.3     , 0.333333, 0.4     , 0.466667, 0.5     , 0.533333, 0.6     , 0.666667, 0.7     ,\n        0.733333, 0.8     , 0.866667, 0.9     , 0.933333, 1.      ]),\n array([0.      , 0.333333, 0.5     , 0.666667, 1.      ]),\n array([0.      , 0.333333, 0.5     , 0.666667, 1.      ]),\n array([0.      , 0.333333, 0.5     , 0.666667, 1.      ]),\n array([0.333333, 0.444444, 0.5     , 0.555556, 0.666667, 0.777778, 0.833333, 0.888889, 1.      ])]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 20
    }
   ],
   "source": [
    "unique_sorted_values=[np.sort(train[labels[i]].unique()) for i in range(len(labels))]\n",
    "unique_sorted_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['question_asker_intent_understanding',\n 'question_body_critical',\n 'question_conversational',\n 'question_expect_short_answer',\n 'question_fact_seeking',\n 'question_has_commonly_accepted_answer',\n 'question_interestingness_others',\n 'question_interestingness_self',\n 'question_multi_intent',\n 'question_not_really_a_question',\n 'question_opinion_seeking',\n 'question_type_choice',\n 'question_type_compare',\n 'question_type_consequence',\n 'question_type_definition',\n 'question_type_entity',\n 'question_type_instructions',\n 'question_type_procedure',\n 'question_type_reason_explanation',\n 'question_type_spelling',\n 'question_well_written',\n 'answer_helpful',\n 'answer_level_of_information',\n 'answer_plausible',\n 'answer_relevance',\n 'answer_satisfaction',\n 'answer_type_instructions',\n 'answer_type_procedure',\n 'answer_type_reason_explanation',\n 'answer_well_written']"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 21
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "from gquest_nbdev.fastai_huggingface import * "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "train['host']=train['host'].astype('category')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mixed_list= MixedObjectList.from_df([train,train], cols_list=[['question_title_body','answer'],['host']], \n",
    "                 processors=[transformer_processor,transformer_processor],item_type_list=[TextList_Multi,TabularList])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "gquest_nbdev.fastai_huggingface.MixedObjectList"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 40
    }
   ],
   "source": [
    "type(mixed_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "sd_multi = (mixed_list.split_subsets(train_size=0.8,valid_size=0.2))\n",
    "                #.split_by_rand_pct(0.1,seed=seed)\n",
    "                 "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "gquest_nbdev.fastai_huggingface.MixedObjectLists"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 42
    }
   ],
   "source": [
    "type(sd_multi)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n      \n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n      \n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sd_label_multi = (sd_multi.label_from_df(cols=labels,label_cls=MultiCategoryList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "gquest_nbdev.fastai_huggingface.LabelLists_Multi"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 51
    }
   ],
   "source": [
    "type(sd_label_multi)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-7c6885a6c6d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# pydev_debug_cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdatabunch_multi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msd_label_multi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatabunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/fastai/data_block.py\u001b[0m in \u001b[0;36mdatabunch\u001b[0;34m(self, path, bs, val_bs, num_workers, dl_tfms, device, collate_fn, no_check, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m                   no_check:bool=False, **kwargs)->'DataBunch':\n\u001b[1;32m    547\u001b[0m         \u001b[0;34m\"Create an `DataBunch` from self, `path` will override `self.path`, `kwargs` are passed to `DataBunch.create`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mifnone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m         data = self.x._bunch.create(self.train, self.valid, test_ds=self.test, path=path, bs=bs, val_bs=val_bs,\n\u001b[1;32m    550\u001b[0m                                     num_workers=num_workers, dl_tfms=dl_tfms, device=device, collate_fn=collate_fn, no_check=no_check, **kwargs)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/fastai/data_block.py\u001b[0m in \u001b[0;36mdatabunch\u001b[0;34m(self, path, bs, val_bs, num_workers, dl_tfms, device, collate_fn, no_check, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m                   no_check:bool=False, **kwargs)->'DataBunch':\n\u001b[1;32m    547\u001b[0m         \u001b[0;34m\"Create an `DataBunch` from self, `path` will override `self.path`, `kwargs` are passed to `DataBunch.create`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mifnone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m         data = self.x._bunch.create(self.train, self.valid, test_ds=self.test, path=path, bs=bs, val_bs=val_bs,\n\u001b[1;32m    550\u001b[0m                                     num_workers=num_workers, dl_tfms=dl_tfms, device=device, collate_fn=collate_fn, no_check=no_check, **kwargs)\n",
      "\u001b[0;32m/snap/pycharm-professional/179/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_frame.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# if thread has a suspend flag, we suspend with a busy wait\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpydev_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSTATE_SUSPEND\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_wait_suspend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m                     \u001b[0;31m# No need to reset frame.f_trace to keep the same trace function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/snap/pycharm-professional/179/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_frame.py\u001b[0m in \u001b[0;36mdo_wait_suspend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_wait_suspend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_wait_suspend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;31m# IFDEF CYTHON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/snap/pycharm-professional/179/plugins/python/helpers/pydev/pydevd.py\u001b[0m in \u001b[0;36mdo_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_threads_suspended_single_notification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify_thread_suspended\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthread_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_wait_suspend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuspend_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_this_thread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_wait_suspend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuspend_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_this_thread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/snap/pycharm-professional/179/plugins/python/helpers/pydev/pydevd.py\u001b[0m in \u001b[0;36m_do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001b[0m\n\u001b[1;32m   1112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_internal_commands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancel_async_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_current_thread_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error"
    }
   ],
   "source": [
    "\n",
    "databunch_multi=sd_label_multi.databunch(bs=bs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "sd = (TextList_Multi.from_df(train, cols=['question_title_body','answer'], \n",
    "                 processor=transformer_processor)\n",
    "                .split_none()\n",
    "                #.split_by_rand_pct(0.1,seed=seed)\n",
    "                  #.split_subsets(train_size=0.8,valid_size=0.2)\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "type(sd)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sd_label=sd.label_from_df(cols=labels,label_cls=MultiCategoryList)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "type(sd)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "databunch = (sd.add_test(test[['question_title_body','answer']])\n",
    "                .databunch(bs=bs))  \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#print('[CLS] token :', transformer_tokenizer.cls_token)\n",
    "#print('[SEP] token :', transformer_tokenizer.sep_token)\n",
    "#print('[PAD] token :', transformer_tokenizer.pad_token)\n",
    "#databunch.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check batch and numericalizer :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#print('[CLS] id :', transformer_tokenizer.cls_token_id)\n",
    "#print('[SEP] id :', transformer_tokenizer.sep_token_id)\n",
    "#print('[PAD] id :', pad_idx)\n",
    "test_one_batch = databunch.one_batch()\n",
    "#print('Batch shape : ',test_one_batch.shape)\n",
    "print(test_one_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_one_batch[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the transformer adapted to multiclass classification, we need to specify the number of labels before loading the pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if download_model:\n",
    "    config = config_class.from_pretrained(pretrained_model_name)\n",
    "    config.save_pretrained(MODEL_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "config = config_class.from_pretrained(MODEL_ROOT,num_labels=200)\n",
    "config.use_bfloat16 = use_fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if download_model:\n",
    "    transformer_model_q = model_class.from_pretrained(pretrained_model_name, config = config)\n",
    "    transformer_model_a = model_class.from_pretrained(pretrained_model_name, config = config)\n",
    "    transformer_model_a.save_pretrained(MODEL_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if not download_model:\n",
    "    transformer_model_q = model_class.from_pretrained(MODEL_ROOT, config = config)\n",
    "    transformer_model_a = model_class.from_pretrained(MODEL_ROOT, config = config)\n",
    "custom_transformer_model = CustomTransformerModel(transformer_model_q = transformer_model_q,transformer_model_a=transformer_model_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class AvgSpearman2(Callback):\n",
    "    \n",
    "    def __init__(self, labels,*args,**kwargs):\n",
    "        super().__init__(*args,**kwargs)\n",
    "        self.labels=labels\n",
    "    \n",
    "    def on_epoch_begin(self, **kwargs):\n",
    "        self.preds = np.empty( shape=(0, 200) )\n",
    "        self.target = np.empty( shape=(0,30) )\n",
    "    \n",
    "    def on_batch_end(self, last_output, last_target, **kwargs):\n",
    "        self.preds = np.append(self.preds,last_output.cpu(),axis=0)\n",
    "        self.target = np.append(self.target,last_target.cpu(),axis=0)\n",
    "    \n",
    "    def on_epoch_end(self, last_metrics, **kwargs):\n",
    "        pos = 0\n",
    "        spearsum=0.0\n",
    "        for i in range(self.target.shape[1]):\n",
    "            column_distinct_size = len(self.labels[i])\n",
    "            #pdb.set_trace()\n",
    "            processed_target = self.target[:,i]\n",
    "            processed_pred = self.labels[i][torch.argmax(torch.tensor(self.preds[:,pos:(pos+column_distinct_size)]),1)]\n",
    "            #processed_pred = torch.matmul(F.softmax(torch.tensor(self.preds[:,pos:(pos+column_distinct_size)]),1),torch.tensor(self.labels[i]))\n",
    "            spearnew=spearmanr(processed_pred,processed_target).correlation\n",
    "            print(spearnew)\n",
    "            spearsum +=spearnew\n",
    "            \n",
    "            pos +=column_distinct_size\n",
    "        res = spearsum/self.target.shape[1]\n",
    "        return add_metrics(last_metrics, res)        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "weights = torch.tensor(train[labels[0]].value_counts(normalize=True).sort_values().values,dtype=torch.float32).cuda()\n",
    "weights=(1/weights)/(1/weights).sum()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from fastai.callbacks import *\n",
    "from transformers import AdamW\n",
    "\n",
    "from functools import partial\n",
    "AdamW = partial(AdamW, correct_bias=False)\n",
    "\n",
    "learner = Learner(databunch, \n",
    "                  custom_transformer_model, \n",
    "                  opt_func = AdamW,\n",
    "                  loss_func = CrossEntropyFlat_BWW(unique_sorted_values=unique_sorted_values),\n",
    "                  metrics=[AvgSpearman(unique_sorted_values)]\n",
    "                )\n",
    "\n",
    "# Show graph of learner stats and metrics after each epoch.\n",
    "#learner.callbacks.append(ShowGraph(learner))\n",
    "\n",
    "# Put learn in FP16 precision mode. --> Not working in the tutorial\n",
    "if use_fp16: learner = learner.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(learner.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how many layer groups we currently have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "num_groups = len(learner.layer_groups)\n",
    "print('Learner split in',num_groups,'groups')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One group won't allow us to unfreeze parts of the model. The tutorial kernel suggested to divide the RoBERTa model in 14 blocks:\n",
    "* 1 Embedding\n",
    "* 12 transformer\n",
    "* 1 classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "list_layers = [learner.model.transformer.roberta.embeddings,\n",
    "              learner.model.transformer.roberta.encoder.layer[0],\n",
    "              learner.model.transformer.roberta.encoder.layer[1],\n",
    "              learner.model.transformer.roberta.encoder.layer[2],\n",
    "              learner.model.transformer.roberta.encoder.layer[3],\n",
    "              learner.model.transformer.roberta.encoder.layer[4],\n",
    "              learner.model.transformer.roberta.encoder.layer[5],\n",
    "              learner.model.transformer.roberta.encoder.layer[6],\n",
    "              learner.model.transformer.roberta.encoder.layer[7],\n",
    "              learner.model.transformer.roberta.encoder.layer[8],\n",
    "              learner.model.transformer.roberta.encoder.layer[9],\n",
    "              learner.model.transformer.roberta.encoder.layer[10],\n",
    "              learner.model.transformer.roberta.encoder.layer[11],\n",
    "              learner.model.transformer.roberta.pooler]\n",
    "\n",
    "learner.split(list_layers);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "#list_layers = [learner.model.transformer.albert.embeddings,\n",
    "#              learner.model.transformer.albert.encoder.albert_layer_groups[0],\n",
    "#              learner.model.transformer.albert.pooler]\n",
    "\n",
    "list_layers = [learner.model.transformer.embeddings,\n",
    "              learner.model.transformer.encoder.layer[0],\n",
    "              learner.model.transformer.encoder.layer[1],\n",
    "              learner.model.transformer.encoder.layer[2],\n",
    "              learner.model.transformer.encoder.layer[3],\n",
    "              learner.model.transformer.encoder.layer[4],\n",
    "              learner.model.transformer.encoder.layer[5],\n",
    "              learner.model.transformer.encoder.layer[6],\n",
    "              learner.model.transformer.encoder.layer[7],\n",
    "              learner.model.transformer.encoder.layer[8],\n",
    "              learner.model.transformer.encoder.layer[9],\n",
    "              learner.model.transformer.encoder.layer[10],\n",
    "              learner.model.transformer.encoder.layer[11],\n",
    "              learner.model.transformer.pooler,\n",
    "              learner.model.classifier]\n",
    "\n",
    "#learner.split(list_layers);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that we now have 14 layer groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "num_groups = len(learner.layer_groups)\n",
    "print('Learner split in',num_groups,'groups')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the model we will:\n",
    "1. Find an appropriate initial learning rate\n",
    "1. Progressively unfreeze the layers while training\n",
    "\n",
    "During all training, we use the **Slanted Triangular Learning Rates** with the `.fit_one_cycle` command, described [here](https://docs.fast.ai/callbacks.one_cycle.html). Originally, I wanted to unfreeze the entire model, but I kept running out of space. I'll trouble shoot in other versions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "unfreeze_layers = [-1,-2,-3]\n",
    "learning_rates = [3e-4, 1e-5, 5e-6]\n",
    "epochs = [3,4,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "unfreeze_layers = [-1,-5,-9,-15]\n",
    "learning_rates = [2e-4, 5e-5,  5e-5, 1e-5]\n",
    "epochs = [2, 2, 3,4]\n",
    "learner.loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def model_unfreezing_and_training(num_groups,learning_rates,unfreeze_layers,epochs):\n",
    "    for layer in range(0,num_groups):\n",
    "        print(layer)\n",
    "        if layer == num_groups-1: \n",
    "            learner.unfreeze()     \n",
    "        else: \n",
    "            learner.freeze_to(unfreeze_layers[layer])\n",
    "        \n",
    "        print('freezing to:',unfreeze_layers[layer],' - ',epochs[layer],'epochs')\n",
    "        learner.fit_one_cycle(epochs[layer], \n",
    "                              max_lr=slice(learning_rates[layer]*0.95**num_groups, learning_rates[layer]),\n",
    "                              moms=(0.8, 0.9))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "learner.fit_one_cycle(6, \n",
    "                              max_lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "learner.fit_one_cycle(20, \n",
    "                              max_lr=1e-5,\n",
    "                              moms=(0.8, 0.9))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model_unfreezing_and_training() #bce loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model_unfreezing_and_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions and Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is trained, we can generate our predictions from the test dataset. As [noted in other tutorials](https://mlexplained.com/2019/05/13/a-tutorial-to-fine-tuning-bert-with-fast-ai/) the function ``get_preds`` does not return elements in order by default. Therefore, we will have to resort the test elements into their correct order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def get_preds_as_nparray(ds_type,unique_sorted_values,databunch)  -> np.ndarray:\n",
    "    \"\"\"\n",
    "    the get_preds method does not yield the elements in order by default\n",
    "    we borrow the code from the RNNLearner to resort the elements into their correct order\n",
    "    \"\"\"\n",
    "    preds = learner.get_preds(ds_type)[0].detach().cpu().numpy()\n",
    "    pos =0\n",
    "    processed_pred=torch.empty(preds.shape[0],30)\n",
    "    for j in range(len(unique_sorted_values)):\n",
    "        column_distinct_size = len(unique_sorted_values[j])\n",
    "        #processed_pred = self.labels[torch.argmax(torch.tensor(self.preds),1)]\n",
    "        processed_pred[:,j] = torch.matmul(F.softmax(torch.tensor(preds[:,pos:(pos+column_distinct_size)]),1),\n",
    "                                        torch.tensor(unique_sorted_values[j],dtype=torch.float))\n",
    "        pos+=column_distinct_size\n",
    "    processed_pred=processed_pred.numpy()\n",
    "    sampler = [i for i in databunch.dl(ds_type).sampler]\n",
    "    reverse_sampler = np.argsort(sampler)\n",
    "    return processed_pred[reverse_sampler, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "x = np.arange(10,1,-1)\n",
    "labels=np.random.randn(9)\n",
    "labels[a.astype(int)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "test_preds,test_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "test_preds,test_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(DATA_ROOT / 'sample_submission.csv')\n",
    "sample_submission[labels] = test_preds\n",
    "sample_submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check the order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}