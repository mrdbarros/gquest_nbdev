{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up and Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This kernel uses fastai and Huggingface transformser. fastai is already installed on Kaggle, and [here](https://www.kaggle.com/c/tensorflow2-question-answering/discussion/117716) is a discussion post that shows how to get Huggingface installled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This statement prints all of the directories in the /kaggle/input/ directory. This can be useful when trying to determine the path of the external datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from gquest_nbdev.fastai_huggingface import * \n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import pdb\n",
    "from pathlib import Path \n",
    "from fastai.text import *\n",
    "from fastai.tabular import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    print(dirname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A utility function to set the seed for generating random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "seed=42\n",
    "seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#os.chdir(Path(\"./gquest_nbdev\"))\n",
    "#os.chdir(Path(\"/home/mrdbarros/projetos/gquest_nbdev\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6079, 41) (476, 11)\n"
     ]
    }
   ],
   "source": [
    "model_type = 'roberta'\n",
    "pretrained_model_name = 'roberta-base' # 'roberta-base-openai-detector'\n",
    "DATA_ROOT = Path(\"../input/google-quest-challenge/\")\n",
    "MODEL_ROOT = Path(\"../input/\"+pretrained_model_name)\n",
    "train = pd.read_csv(DATA_ROOT / 'train.csv')\n",
    "test = pd.read_csv(DATA_ROOT / 'test.csv')\n",
    "sample_sub = pd.read_csv(DATA_ROOT / 'sample_submission.csv')\n",
    "print(train.shape,test.shape)\n",
    "download_model=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data. In this kernel, I'll use the `question_title`, `question_body` and `answer` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_title</th>\n",
       "      <th>question_body</th>\n",
       "      <th>question_user_name</th>\n",
       "      <th>question_user_page</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_user_name</th>\n",
       "      <th>answer_user_page</th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>What am I losing when using extension tubes in...</td>\n",
       "      <td>After playing around with macro photography on...</td>\n",
       "      <td>ysap</td>\n",
       "      <td>https://photo.stackexchange.com/users/1024</td>\n",
       "      <td>I just got extension tubes, so here's the skin...</td>\n",
       "      <td>rfusca</td>\n",
       "      <td>https://photo.stackexchange.com/users/1917</td>\n",
       "      <td>http://photo.stackexchange.com/questions/9169/...</td>\n",
       "      <td>LIFE_ARTS</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the distinction between a city and a s...</td>\n",
       "      <td>I am trying to understand what kinds of places...</td>\n",
       "      <td>russellpierce</td>\n",
       "      <td>https://rpg.stackexchange.com/users/8774</td>\n",
       "      <td>It might be helpful to look into the definitio...</td>\n",
       "      <td>Erik Schmidt</td>\n",
       "      <td>https://rpg.stackexchange.com/users/1871</td>\n",
       "      <td>http://rpg.stackexchange.com/questions/47820/w...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Maximum protusion length for through-hole comp...</td>\n",
       "      <td>I'm working on a PCB that has through-hole com...</td>\n",
       "      <td>Joe Baker</td>\n",
       "      <td>https://electronics.stackexchange.com/users/10157</td>\n",
       "      <td>Do you even need grooves?  We make several pro...</td>\n",
       "      <td>Dwayne Reid</td>\n",
       "      <td>https://electronics.stackexchange.com/users/64754</td>\n",
       "      <td>http://electronics.stackexchange.com/questions...</td>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Can an affidavit be used in Beit Din?</td>\n",
       "      <td>An affidavit, from what i understand, is basic...</td>\n",
       "      <td>Scimonster</td>\n",
       "      <td>https://judaism.stackexchange.com/users/5151</td>\n",
       "      <td>Sending an \"affidavit\" it is a dispute between...</td>\n",
       "      <td>Y     e     z</td>\n",
       "      <td>https://judaism.stackexchange.com/users/4794</td>\n",
       "      <td>http://judaism.stackexchange.com/questions/551...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>How do you make a binary image in Photoshop?</td>\n",
       "      <td>I am trying to make a binary image. I want mor...</td>\n",
       "      <td>leigero</td>\n",
       "      <td>https://graphicdesign.stackexchange.com/users/...</td>\n",
       "      <td>Check out Image Trace in Adobe Illustrator. \\n...</td>\n",
       "      <td>q2ra</td>\n",
       "      <td>https://graphicdesign.stackexchange.com/users/...</td>\n",
       "      <td>http://graphicdesign.stackexchange.com/questio...</td>\n",
       "      <td>LIFE_ARTS</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id                                     question_title  \\\n",
       "0      0  What am I losing when using extension tubes in...   \n",
       "1      1  What is the distinction between a city and a s...   \n",
       "2      2  Maximum protusion length for through-hole comp...   \n",
       "3      3              Can an affidavit be used in Beit Din?   \n",
       "4      5       How do you make a binary image in Photoshop?   \n",
       "\n",
       "                                       question_body question_user_name  \\\n",
       "0  After playing around with macro photography on...               ysap   \n",
       "1  I am trying to understand what kinds of places...      russellpierce   \n",
       "2  I'm working on a PCB that has through-hole com...          Joe Baker   \n",
       "3  An affidavit, from what i understand, is basic...         Scimonster   \n",
       "4  I am trying to make a binary image. I want mor...            leigero   \n",
       "\n",
       "                                  question_user_page  \\\n",
       "0         https://photo.stackexchange.com/users/1024   \n",
       "1           https://rpg.stackexchange.com/users/8774   \n",
       "2  https://electronics.stackexchange.com/users/10157   \n",
       "3       https://judaism.stackexchange.com/users/5151   \n",
       "4  https://graphicdesign.stackexchange.com/users/...   \n",
       "\n",
       "                                              answer answer_user_name  \\\n",
       "0  I just got extension tubes, so here's the skin...           rfusca   \n",
       "1  It might be helpful to look into the definitio...     Erik Schmidt   \n",
       "2  Do you even need grooves?  We make several pro...      Dwayne Reid   \n",
       "3  Sending an \"affidavit\" it is a dispute between...    Y     e     z   \n",
       "4  Check out Image Trace in Adobe Illustrator. \\n...             q2ra   \n",
       "\n",
       "                                    answer_user_page  \\\n",
       "0         https://photo.stackexchange.com/users/1917   \n",
       "1           https://rpg.stackexchange.com/users/1871   \n",
       "2  https://electronics.stackexchange.com/users/64754   \n",
       "3       https://judaism.stackexchange.com/users/4794   \n",
       "4  https://graphicdesign.stackexchange.com/users/...   \n",
       "\n",
       "                                                 url   category  ...  \\\n",
       "0  http://photo.stackexchange.com/questions/9169/...  LIFE_ARTS  ...   \n",
       "1  http://rpg.stackexchange.com/questions/47820/w...    CULTURE  ...   \n",
       "2  http://electronics.stackexchange.com/questions...    SCIENCE  ...   \n",
       "3  http://judaism.stackexchange.com/questions/551...    CULTURE  ...   \n",
       "4  http://graphicdesign.stackexchange.com/questio...  LIFE_ARTS  ...   \n",
       "\n",
       "  question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "0              1.000000        1.000000                     0.666667   \n",
       "1              0.888889        0.888889                     0.555556   \n",
       "2              0.777778        0.777778                     0.555556   \n",
       "3              0.888889        0.833333                     0.333333   \n",
       "4              1.000000        1.000000                     0.666667   \n",
       "\n",
       "   answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "0          1.000000          1.000000             0.800000   \n",
       "1          0.888889          0.888889             0.666667   \n",
       "2          1.000000          1.000000             0.666667   \n",
       "3          0.833333          1.000000             0.800000   \n",
       "4          1.000000          1.000000             0.800000   \n",
       "\n",
       "   answer_type_instructions  answer_type_procedure  \\\n",
       "0                       1.0               0.000000   \n",
       "1                       0.0               0.000000   \n",
       "2                       0.0               0.333333   \n",
       "3                       0.0               0.000000   \n",
       "4                       1.0               0.000000   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.000000             1.000000  \n",
       "1                        0.666667             0.888889  \n",
       "2                        1.000000             0.888889  \n",
       "3                        1.000000             1.000000  \n",
       "4                        1.000000             1.000000  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted lables are in the columns of the sample submission. Note that some labels are with respect to the question, and some are with respect to the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "labels = list(sample_sub.columns[1:].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question_asker_intent_understanding\n",
      "question_body_critical\n",
      "question_conversational\n",
      "question_expect_short_answer\n",
      "question_fact_seeking\n",
      "question_has_commonly_accepted_answer\n",
      "question_interestingness_others\n",
      "question_interestingness_self\n",
      "question_multi_intent\n",
      "question_not_really_a_question\n",
      "question_opinion_seeking\n",
      "question_type_choice\n",
      "question_type_compare\n",
      "question_type_consequence\n",
      "question_type_definition\n",
      "question_type_entity\n",
      "question_type_instructions\n",
      "question_type_procedure\n",
      "question_type_reason_explanation\n",
      "question_type_spelling\n",
      "question_well_written\n",
      "answer_helpful\n",
      "answer_level_of_information\n",
      "answer_plausible\n",
      "answer_relevance\n",
      "answer_satisfaction\n",
      "answer_type_instructions\n",
      "answer_type_procedure\n",
      "answer_type_reason_explanation\n",
      "answer_well_written\n"
     ]
    }
   ],
   "source": [
    "for label in labels: print(label) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "train[['question_title','question_body','answer']].to_csv(Path('../input/raw_text.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "seed = 42\n",
    "use_fp16 = True\n",
    "bs = 8\n",
    "MAX_SEQUENCE_LENGTH = 512\n",
    "#train=train[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "model_class, tokenizer_class, config_class = MODEL_CLASSES[model_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘../input/roberta-base’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "if download_model:\n",
    "    new_dir=Path(\"../input\")/pretrained_model_name\n",
    "    !mkdir {new_dir}\n",
    "    transformer_tokenizer = tokenizer_class.from_pretrained(pretrained_model_name)\n",
    "    transformer_tokenizer.save_pretrained(MODEL_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['roberta-base', 'roberta-large', 'roberta-large-mnli', 'distilroberta-base', 'roberta-base-openai-detector', 'roberta-large-openai-detector'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_class.pretrained_model_archive_map.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train['question_title_body']=train['question_title'] +\" \" + train['question_body']\n",
    "test['question_title_body']=test['question_title'] +\" \" + test['question_body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "if download_model:\n",
    "    transformer_tokenizer = tokenizer_class.from_pretrained(pretrained_model_name)\n",
    "    transformer_tokenizer.save_pretrained(MODEL_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "transformer_tokenizer = tokenizer_class.from_pretrained(MODEL_ROOT)\n",
    "transformer_base_tokenizer = TransformersBaseTokenizer(pretrained_tokenizer = transformer_tokenizer, model_type = model_type)\n",
    "fastai_tokenizer = Tokenizer_MultiColumn(tok_func = transformer_base_tokenizer, pre_rules=[], post_rules=[]#,n_cpus=1\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "transformer_vocab =  TransformersVocab(tokenizer = transformer_tokenizer)\n",
    "numericalize_processor = NumericalizeProcessor(vocab=transformer_vocab)\n",
    "\n",
    "tokenize_processor = TokenizeProcessorDualBert(tokenizer=fastai_tokenizer, include_bos=False, include_eos=False)\n",
    "\n",
    "transformer_processor = [tokenize_processor, numericalize_processor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "pad_first = bool(model_type in ['xlnet'])\n",
    "pad_idx = transformer_tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.333333, 0.444444, 0.5     , 0.555556, 0.666667, 0.777778, 0.833333, 0.888889, 1.      ]),\n",
       " array([0.333333, 0.444444, 0.5     , 0.555556, 0.666667, 0.777778, 0.833333, 0.888889, 1.      ]),\n",
       " array([0.      , 0.333333, 0.5     , 0.666667, 1.      ]),\n",
       " array([0.      , 0.333333, 0.5     , 0.666667, 1.      ]),\n",
       " array([0.      , 0.333333, 0.5     , 0.666667, 1.      ]),\n",
       " array([0.      , 0.333333, 0.5     , 0.666667, 1.      ]),\n",
       " array([0.333333, 0.444444, 0.5     , 0.555556, 0.666667, 0.777778, 0.833333, 0.888889, 1.      ]),\n",
       " array([0.333333, 0.444444, 0.5     , 0.555556, 0.666667, 0.777778, 0.833333, 0.888889, 1.      ]),\n",
       " array([0.      , 0.333333, 0.5     , 0.666667, 1.      ]),\n",
       " array([0.      , 0.333333, 0.5     , 0.666667, 1.      ]),\n",
       " array([0.      , 0.333333, 0.5     , 0.666667, 1.      ]),\n",
       " array([0.      , 0.333333, 0.5     , 0.666667, 1.      ]),\n",
       " array([0.      , 0.333333, 0.5     , 0.666667, 1.      ]),\n",
       " array([0.      , 0.333333, 0.5     , 0.666667, 1.      ]),\n",
       " array([0.      , 0.333333, 0.5     , 0.666667, 1.      ]),\n",
       " array([0.      , 0.333333, 0.5     , 0.666667, 1.      ]),\n",
       " array([0.      , 0.333333, 0.5     , 0.666667, 1.      ]),\n",
       " array([0.      , 0.333333, 0.5     , 0.666667, 1.      ]),\n",
       " array([0.      , 0.333333, 0.5     , 0.666667, 1.      ]),\n",
       " array([0.      , 0.333333, 0.666667]),\n",
       " array([0.333333, 0.444444, 0.5     , 0.555556, 0.666667, 0.777778, 0.833333, 0.888889, 1.      ]),\n",
       " array([0.333333, 0.444444, 0.5     , 0.555556, 0.666667, 0.777778, 0.833333, 0.888889, 1.      ]),\n",
       " array([0.333333, 0.444444, 0.5     , 0.555556, 0.666667, 0.777778, 0.833333, 0.888889, 1.      ]),\n",
       " array([0.333333, 0.444444, 0.5     , 0.555556, 0.666667, 0.777778, 0.833333, 0.888889, 1.      ]),\n",
       " array([0.333333, 0.444444, 0.5     , 0.555556, 0.666667, 0.777778, 0.833333, 0.888889, 1.      ]),\n",
       " array([0.2     , 0.266667, 0.3     , 0.333333, 0.4     , 0.466667, 0.5     , 0.533333, 0.6     , 0.666667, 0.7     ,\n",
       "        0.733333, 0.8     , 0.866667, 0.9     , 0.933333, 1.      ]),\n",
       " array([0.      , 0.333333, 0.5     , 0.666667, 1.      ]),\n",
       " array([0.      , 0.333333, 0.5     , 0.666667, 1.      ]),\n",
       " array([0.      , 0.333333, 0.5     , 0.666667, 1.      ]),\n",
       " array([0.333333, 0.444444, 0.5     , 0.555556, 0.666667, 0.777778, 0.833333, 0.888889, 1.      ])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_sorted_values=[np.sort(train[labels[i]].unique()) for i in range(len(labels))]\n",
    "unique_sorted_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['question_asker_intent_understanding',\n",
       " 'question_body_critical',\n",
       " 'question_conversational',\n",
       " 'question_expect_short_answer',\n",
       " 'question_fact_seeking',\n",
       " 'question_has_commonly_accepted_answer',\n",
       " 'question_interestingness_others',\n",
       " 'question_interestingness_self',\n",
       " 'question_multi_intent',\n",
       " 'question_not_really_a_question',\n",
       " 'question_opinion_seeking',\n",
       " 'question_type_choice',\n",
       " 'question_type_compare',\n",
       " 'question_type_consequence',\n",
       " 'question_type_definition',\n",
       " 'question_type_entity',\n",
       " 'question_type_instructions',\n",
       " 'question_type_procedure',\n",
       " 'question_type_reason_explanation',\n",
       " 'question_type_spelling',\n",
       " 'question_well_written',\n",
       " 'answer_helpful',\n",
       " 'answer_level_of_information',\n",
       " 'answer_plausible',\n",
       " 'answer_relevance',\n",
       " 'answer_satisfaction',\n",
       " 'answer_type_instructions',\n",
       " 'answer_type_procedure',\n",
       " 'answer_type_reason_explanation',\n",
       " 'answer_well_written']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from gquest_nbdev.fastai_huggingface import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train['host']=train['host'].astype('category')\n",
    "train['category']=train['category'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mixed_list= MixedObjectList.from_df([train,train], cols_list=[['question_title_body','answer'],['category','host']], \n",
    "                 processors=[transformer_processor,transformer_processor],item_type_list=[TextList_Multi,TabularList])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gquest_nbdev.fastai_huggingface.MixedObjectList"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mixed_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sd_multi = (mixed_list.split_subsets(train_size=0.8,valid_size=0.2))\n",
    "                #.split_by_rand_pct(0.1,seed=seed)\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gquest_nbdev.fastai_huggingface.MixedObjectLists"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sd_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sd_label_multi = (sd_multi.label_from_df(cols=labels\n",
    "                                         #,label_cls=MultiCategoryList\n",
    "                                         )\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gquest_nbdev.fastai_huggingface.LabelLists_Multi"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sd_label_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "databunch_multi=sd_label_multi.databunch(bs=bs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#print('[CLS] token :', transformer_tokenizer.cls_token)\n",
    "#print('[SEP] token :', transformer_tokenizer.sep_token)\n",
    "#print('[PAD] token :', transformer_tokenizer.pad_token)\n",
    "#databunch.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check batch and numericalizer :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[[    0,  2264,   473,  ...,     1,     1,     1],\n",
      "          [    1,     1,     1,  ...,     0,     0,     0],\n",
      "          [    0,     0,     0,  ...,     0,     0,     0]],\n",
      "\n",
      "         [[    0,  1620,    13,  ...,     1,     1,     1],\n",
      "          [    1,     1,     1,  ...,     0,     0,     0],\n",
      "          [    0,     0,     0,  ...,     0,     0,     0]]],\n",
      "\n",
      "\n",
      "        [[[    0, 27847,    22,  ...,     1,     1,     1],\n",
      "          [    1,     1,     1,  ...,     0,     0,     0],\n",
      "          [    0,     0,     0,  ...,     0,     0,     0]],\n",
      "\n",
      "         [[    0,   113,  2847,  ...,     1,     1,     1],\n",
      "          [    1,     1,     1,  ...,     0,     0,     0],\n",
      "          [    0,     0,     0,  ...,     0,     0,     0]]],\n",
      "\n",
      "\n",
      "        [[[    0,  7608,   473,  ...,     1,     1,     1],\n",
      "          [    1,     1,     1,  ...,     0,     0,     0],\n",
      "          [    0,     0,     0,  ...,     0,     0,     0]],\n",
      "\n",
      "         [[    0, 46766, 18634,  ...,     1,     1,     1],\n",
      "          [    1,     1,     1,  ...,     0,     0,     0],\n",
      "          [    0,     0,     0,  ...,     0,     0,     0]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[    0, 49392,     5,  ...,     1,     1,     1],\n",
      "          [    1,     1,     1,  ...,     0,     0,     0],\n",
      "          [    0,     0,     0,  ...,     0,     0,     0]],\n",
      "\n",
      "         [[    0,   100,   761,  ...,     1,     1,     1],\n",
      "          [    1,     1,     1,  ...,     0,     0,     0],\n",
      "          [    0,     0,     0,  ...,     0,     0,     0]]],\n",
      "\n",
      "\n",
      "        [[[    0, 46620,   154,  ...,     1,     1,     1],\n",
      "          [    1,     1,     1,  ...,     0,     0,     0],\n",
      "          [    0,     0,     0,  ...,     0,     0,     0]],\n",
      "\n",
      "         [[    0,   243,    34,  ...,     1,     1,     1],\n",
      "          [    1,     1,     1,  ...,     0,     0,     0],\n",
      "          [    0,     0,     0,  ...,     0,     0,     0]]],\n",
      "\n",
      "\n",
      "        [[[    0,  6179,     7,  ...,     1,     1,     1],\n",
      "          [    1,     1,     1,  ...,     0,     0,     0],\n",
      "          [    0,     0,     0,  ...,     0,     0,     0]],\n",
      "\n",
      "         [[    0,  1106,    47,  ...,     1,     1,     1],\n",
      "          [    1,     1,     1,  ...,     0,     0,     0],\n",
      "          [    0,     0,     0,  ...,     0,     0,     0]]]]), tensor([[0.7778, 0.6667, 0.0000, 0.6667, 1.0000, 1.0000, 0.6667, 0.7778, 0.3333,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3333, 0.6667,\n",
      "         0.3333, 0.0000, 1.0000, 0.8889, 0.5556, 0.8889, 0.8889, 0.8667, 0.0000,\n",
      "         0.6667, 0.6667, 1.0000],\n",
      "        [1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.7778, 0.8889, 0.3333,\n",
      "         0.0000, 0.6667, 1.0000, 0.0000, 0.0000, 0.6667, 0.0000, 0.0000, 0.0000,\n",
      "         0.3333, 0.0000, 1.0000, 1.0000, 0.6667, 1.0000, 1.0000, 0.9333, 0.0000,\n",
      "         0.0000, 0.3333, 1.0000],\n",
      "        [0.5556, 0.4444, 0.0000, 1.0000, 1.0000, 1.0000, 0.5000, 0.5000, 0.3333,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3333,\n",
      "         1.0000, 0.0000, 0.5556, 0.8889, 0.6667, 1.0000, 0.8889, 0.8667, 0.0000,\n",
      "         0.3333, 1.0000, 1.0000],\n",
      "        [1.0000, 0.6667, 0.0000, 1.0000, 0.3333, 1.0000, 0.5556, 0.3333, 0.0000,\n",
      "         0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6667, 0.3333,\n",
      "         0.0000, 0.0000, 0.5556, 1.0000, 0.6667, 1.0000, 1.0000, 0.8667, 1.0000,\n",
      "         0.0000, 0.0000, 1.0000],\n",
      "        [1.0000, 0.8889, 0.0000, 0.6667, 0.6667, 1.0000, 0.4444, 0.3333, 0.0000,\n",
      "         0.0000, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.8889, 1.0000, 0.6667, 1.0000, 1.0000, 0.9333, 0.0000,\n",
      "         0.0000, 1.0000, 0.8889],\n",
      "        [1.0000, 0.3333, 0.0000, 1.0000, 0.3333, 0.0000, 0.6667, 0.6667, 0.0000,\n",
      "         0.0000, 0.6667, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 1.0000, 0.6667, 1.0000, 1.0000, 0.9333, 0.0000,\n",
      "         0.0000, 0.0000, 0.8889],\n",
      "        [0.6667, 0.8333, 0.5000, 0.5000, 1.0000, 1.0000, 0.6667, 0.3333, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5000, 0.5000,\n",
      "         0.5000, 0.0000, 0.6667, 0.8333, 0.6667, 0.8333, 1.0000, 0.8000, 0.5000,\n",
      "         0.5000, 0.5000, 0.6667],\n",
      "        [0.7778, 0.5556, 0.0000, 1.0000, 1.0000, 1.0000, 0.4444, 0.3333, 0.0000,\n",
      "         0.0000, 0.3333, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n",
      "         0.6667, 0.0000, 0.8889, 0.8889, 0.6667, 1.0000, 1.0000, 0.8000, 1.0000,\n",
      "         0.0000, 0.3333, 0.8889]]))\n"
     ]
    }
   ],
   "source": [
    "#print('[CLS] id :', transformer_tokenizer.cls_token_id)\n",
    "#print('[SEP] id :', transformer_tokenizer.sep_token_id)\n",
    "#print('[PAD] id :', pad_idx)\n",
    "test_one_batch = databunch_multi.one_batch()\n",
    "#print('Batch shape : ',test_one_batch.shape)\n",
    "print(test_one_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2, 3, 512])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_one_batch[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the transformer adapted to multiclass classification, we need to specify the number of labels before loading the pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "if download_model:\n",
    "    config = config_class.from_pretrained(pretrained_model_name)\n",
    "    config.save_pretrained(MODEL_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "config = config_class.from_pretrained(MODEL_ROOT,num_labels=200)\n",
    "config.use_bfloat16 = use_fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "if download_model:\n",
    "    transformer_model_q = model_class.from_pretrained(pretrained_model_name, config = config)\n",
    "    transformer_model_a = model_class.from_pretrained(pretrained_model_name, config = config)\n",
    "    transformer_model_a.save_pretrained(MODEL_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train['category'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "if not download_model:\n",
    "    transformer_model_q = model_class.from_pretrained(MODEL_ROOT, config = config)\n",
    "    transformer_model_a = model_class.from_pretrained(MODEL_ROOT, config = config)\n",
    "custom_transformer_model = CustomTransformerModel(transformer_model_q = transformer_model_q,transformer_model_a=transformer_model_a,\n",
    "                                                  emb_sizes=[(len(train['category'].unique())+1,5),(64,20)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5262, 0.1913, 0.1052, 0.0929, 0.0585, 0.0126, 0.0072, 0.0040, 0.0022],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torch.tensor(train[labels[0]].value_counts(normalize=True).sort_values().values,dtype=torch.float32).cuda()\n",
    "weights=(1/weights)/(1/weights).sum()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from fastai.callbacks import *\n",
    "from transformers import AdamW\n",
    "\n",
    "from functools import partial\n",
    "AdamW = partial(AdamW, correct_bias=False)\n",
    "\n",
    "learner = Learner(databunch_multi, \n",
    "                  custom_transformer_model, \n",
    "                  opt_func = AdamW,\n",
    "                  #loss_func = CrossEntropyFlat_BWW(unique_sorted_values=unique_sorted_values),\n",
    "                  #loss_func = MSELossFlat(),\n",
    "                  #metrics=[AvgSpearman(unique_sorted_values)],\n",
    "                  metrics=[AvgSpearman2()],\n",
    "                  callback_fns=[partial(AddExtraBunch)]\n",
    "                )\n",
    "\n",
    "# Show graph of learner stats and metrics after each epoch.\n",
    "#learner.callbacks.append(ShowGraph(learner))\n",
    "\n",
    "# Put learn in FP16 precision mode. --> Not working in the tutorial\n",
    "if use_fp16: learner = learner.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomTransformerModel(\n",
      "  (transformer_q): RobertaModel(\n",
      "    (embeddings): RobertaEmbeddings(\n",
      "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "      (token_type_embeddings): Embedding(1, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (transformer_a): RobertaModel(\n",
      "    (embeddings): RobertaEmbeddings(\n",
      "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "      (token_type_embeddings): Embedding(1, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (classifier): TabularModel(\n",
      "    (embeds): ModuleList(\n",
      "      (0): Embedding(6, 5)\n",
      "      (1): Embedding(64, 20)\n",
      "    )\n",
      "    (emb_drop): Dropout(p=0.0, inplace=False)\n",
      "    (bn_cont): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (layers): Sequential(\n",
      "      (0): Linear(in_features=1561, out_features=800, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "      (4): Linear(in_features=800, out_features=400, bias=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (7): Dropout(p=0.1, inplace=False)\n",
      "      (8): Linear(in_features=400, out_features=30, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(learner.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how many layer groups we currently have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size = 7\n"
     ]
    }
   ],
   "source": [
    "for xb,yb in learner.data.valid_dl:\n",
    "    if xb.shape[0] != 8:\n",
    "        print(\"batch size =\",xb.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size = 7\n"
     ]
    }
   ],
   "source": [
    "for xb,yb in learner.data.secondary_bunch.valid_dl:\n",
    "    #pdb.set_trace()\n",
    "    if xb[0].shape[0] != 8:\n",
    "        print(\"batch size =\",xb[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learner split in 1 groups\n"
     ]
    }
   ],
   "source": [
    "num_groups = len(learner.layer_groups)\n",
    "print('Learner split in',num_groups,'groups')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One group won't allow us to unfreeze parts of the model. The tutorial kernel suggested to divide the RoBERTa model in 14 blocks:\n",
    "* 1 Embedding\n",
    "* 12 transformer\n",
    "* 1 classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "list_layers = [learner.model.transformer.roberta.embeddings,\n",
    "              learner.model.transformer.roberta.encoder.layer[0],\n",
    "              learner.model.transformer.roberta.encoder.layer[1],\n",
    "              learner.model.transformer.roberta.encoder.layer[2],\n",
    "              learner.model.transformer.roberta.encoder.layer[3],\n",
    "              learner.model.transformer.roberta.encoder.layer[4],\n",
    "              learner.model.transformer.roberta.encoder.layer[5],\n",
    "              learner.model.transformer.roberta.encoder.layer[6],\n",
    "              learner.model.transformer.roberta.encoder.layer[7],\n",
    "              learner.model.transformer.roberta.encoder.layer[8],\n",
    "              learner.model.transformer.roberta.encoder.layer[9],\n",
    "              learner.model.transformer.roberta.encoder.layer[10],\n",
    "              learner.model.transformer.roberta.encoder.layer[11],\n",
    "              learner.model.transformer.roberta.pooler]\n",
    "\n",
    "learner.split(list_layers);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "#list_layers = [learner.model.transformer.albert.embeddings,\n",
    "#              learner.model.transformer.albert.encoder.albert_layer_groups[0],\n",
    "#              learner.model.transformer.albert.pooler]\n",
    "\n",
    "list_layers = [learner.model.transformer.embeddings,\n",
    "              learner.model.transformer.encoder.layer[0],\n",
    "              learner.model.transformer.encoder.layer[1],\n",
    "              learner.model.transformer.encoder.layer[2],\n",
    "              learner.model.transformer.encoder.layer[3],\n",
    "              learner.model.transformer.encoder.layer[4],\n",
    "              learner.model.transformer.encoder.layer[5],\n",
    "              learner.model.transformer.encoder.layer[6],\n",
    "              learner.model.transformer.encoder.layer[7],\n",
    "              learner.model.transformer.encoder.layer[8],\n",
    "              learner.model.transformer.encoder.layer[9],\n",
    "              learner.model.transformer.encoder.layer[10],\n",
    "              learner.model.transformer.encoder.layer[11],\n",
    "              learner.model.transformer.pooler,\n",
    "              learner.model.classifier]\n",
    "\n",
    "#learner.split(list_layers);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that we now have 14 layer groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learner split in 1 groups\n"
     ]
    }
   ],
   "source": [
    "num_groups = len(learner.layer_groups)\n",
    "print('Learner split in',num_groups,'groups')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the model we will:\n",
    "1. Find an appropriate initial learning rate\n",
    "1. Progressively unfreeze the layers while training\n",
    "\n",
    "During all training, we use the **Slanted Triangular Learning Rates** with the `.fit_one_cycle` command, described [here](https://docs.fast.ai/callbacks.one_cycle.html). Originally, I wanted to unfreeze the entire model, but I kept running out of space. I'll trouble shoot in other versions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "unfreeze_layers = [-1,-2,-3]\n",
    "learning_rates = [3e-4, 1e-5, 5e-6]\n",
    "epochs = [3,4,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FlattenedLoss of BCEWithLogitsLoss()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unfreeze_layers = [-1,-5,-9,-15]\n",
    "learning_rates = [2e-4, 5e-5,  5e-5, 1e-5]\n",
    "epochs = [2, 2, 3,4]\n",
    "learner.loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def model_unfreezing_and_training(num_groups,learning_rates,unfreeze_layers,epochs):\n",
    "    for layer in range(0,num_groups):\n",
    "        print(layer)\n",
    "        if layer == num_groups-1: \n",
    "            learner.unfreeze()     \n",
    "        else: \n",
    "            learner.freeze_to(unfreeze_layers[layer])\n",
    "        \n",
    "        print('freezing to:',unfreeze_layers[layer],' - ',epochs[layer],'epochs')\n",
    "        learner.fit_one_cycle(epochs[layer], \n",
    "        max_lr=slice(learning_rates[layer]*0.95**num_groups, learning_rates[layer]),\n",
    "                              moms=(0.8, 0.9))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='2' class='' max='3', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      66.67% [2/3 17:15<08:37]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>avg_spearman2</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.066820</td>\n",
       "      <td>0.061252</td>\n",
       "      <td>nan</td>\n",
       "      <td>08:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.069251</td>\n",
       "      <td>0.061037</td>\n",
       "      <td>nan</td>\n",
       "      <td>08:37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='94' class='' max='607', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      15.49% [94/607 01:19<07:15 0.0676]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.fit_one_cycle(3, \n",
    "                              max_lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "learner.fit_one_cycle(20, \n",
    "                              max_lr=1e-5,\n",
    "                              moms=(0.8, 0.9))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>avg_spearman2</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='67' class='' max='607', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      11.04% [67/607 00:59<07:57 0.1712]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learner.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min numerical gradient: 5.75E-06\n",
      "Min loss divided by 10: 1.10E-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.recorder.plot(skip_end=7,suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "model_unfreezing_and_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions and Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is trained, we can generate our predictions from the test dataset. As [noted in other tutorials](https://mlexplained.com/2019/05/13/a-tutorial-to-fine-tuning-bert-with-fast-ai/) the function ``get_preds`` does not return elements in order by default. Therefore, we will have to resort the test elements into their correct order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def get_preds_as_nparray(ds_type,unique_sorted_values,databunch)  -> np.ndarray:\n",
    "    \"\"\"\n",
    "    the get_preds method does not yield the elements in order by default\n",
    "    we borrow the code from the RNNLearner to resort the elements into their correct order\n",
    "    \"\"\"\n",
    "    preds = learner.get_preds(ds_type)[0].detach().cpu().numpy()\n",
    "    pos =0\n",
    "    processed_pred=torch.empty(preds.shape[0],30)\n",
    "    for j in range(len(unique_sorted_values)):\n",
    "        column_distinct_size = len(unique_sorted_values[j])\n",
    "        #processed_pred = self.labels[torch.argmax(torch.tensor(self.preds),1)]\n",
    "        processed_pred[:,j] = torch.matmul(F.softmax(torch.tensor(preds[:,pos:(pos+column_distinct_size)]),1),\n",
    "                                        torch.tensor(unique_sorted_values[j],dtype=torch.float))\n",
    "        pos+=column_distinct_size\n",
    "    processed_pred=processed_pred.numpy()\n",
    "    sampler = [i for i in databunch.dl(ds_type).sampler]\n",
    "    reverse_sampler = np.argsort(sampler)\n",
    "    return processed_pred[reverse_sampler, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x = np.arange(10,1,-1)\n",
    "labels=np.random.randn(9)\n",
    "labels[a.astype(int)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "test_preds,test_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "test_preds,test_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(DATA_ROOT / 'sample_submission.csv')\n",
    "sample_submission[labels] = test_preds\n",
    "sample_submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check the order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
