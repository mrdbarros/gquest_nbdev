{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd # package for high-performance, easy-to-use data structures and data analysis\n",
    "import numpy as np # fundamental package for scientific computing with Python\n",
    "\n",
    "from fastai2.basics import *\n",
    "from fastai2.text.all import *\n",
    "from fastai2.callback.all import *\n",
    "import pickle\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "data_path = Path(\"/home/jupyter/mrdbarros/data/gquest_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "Reading data completed\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "print('Reading data...')\n",
    "train_data = pd.read_csv(data_path/'train/train.csv')\n",
    "test_data = pd.read_csv(data_path/'test/test.csv')\n",
    "sample_submission = pd.read_csv(str(data_path/'sample_submission.csv'))\n",
    "print('Reading data completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['question_asker_intent_understanding', 'question_body_critical',\n",
       "       'question_conversational', 'question_expect_short_answer',\n",
       "       'question_fact_seeking', 'question_has_commonly_accepted_answer',\n",
       "       'question_interestingness_others', 'question_interestingness_self',\n",
       "       'question_multi_intent', 'question_not_really_a_question',\n",
       "       'question_opinion_seeking', 'question_type_choice',\n",
       "       'question_type_compare', 'question_type_consequence',\n",
       "       'question_type_definition', 'question_type_entity',\n",
       "       'question_type_instructions', 'question_type_procedure',\n",
       "       'question_type_reason_explanation', 'question_type_spelling',\n",
       "       'question_well_written', 'answer_helpful',\n",
       "       'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n",
       "       'answer_satisfaction', 'answer_type_instructions',\n",
       "       'answer_type_procedure', 'answer_type_reason_explanation',\n",
       "       'answer_well_written'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#export\n",
    "train_data.columns\n",
    "target_columns = train_data.columns[11:]\n",
    "target_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "with open(data_path/'vocab.pkl', 'rb') as vocab_file:\n",
    " \n",
    "    # Step 3\n",
    "    lm_vocab = pickle.load(vocab_file)\n",
    " \n",
    "    # After config_dictionary is read from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "text_columns=['question_title', 'question_body', 'question_user_name',\n",
    "       'question_user_page', 'answer', 'answer_user_name', 'answer_user_page',\n",
    "       'url', 'category', 'host']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data=train_data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "splits = RandomSplitter()(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "df_tokenized,token_count=tokenize_df(train_data,text_columns)\n",
    "x_tfms = [attrgetter(\"text\"), Numericalize(vocab=lm_vocab)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameToTensor(Transform):\n",
    "    def __init__(self,columns): self.columns=columns\n",
    "    def encodes(self,o): return tensor(o[self.columns].values.astype(float))\n",
    "    def decodes(self,x): return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsrc = DataSource(df_tokenized ,splits=splits, tfms=[x_tfms, [DataFrameToTensor(target_columns)]], dl_type=SortedDL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "dbunch = dsrc.databunch(before_batch=pad_input,bs=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'fastai2.text.data.TensorText'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train=dbunch.train_dl.one_batch()\n",
    "x_valid,y_valid=dbunch.valid_dl.one_batch()\n",
    "print(type(x_valid))\n",
    "print(type(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 10519]) 30 16\n",
      "torch.Size([24, 3836]) 30 24\n",
      "torch.Size([3836])\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape,len(y_train[1]),len(y_train))\n",
    "print(x_valid.shape,len(y_valid[1]),len(y_valid))\n",
    "print(x_valid[1].shape)\n",
    "print(len(y_valid[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#dbunch.show_batch(max_n=2,trunc_at=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spearman_corr_coef(a,b):\n",
    "    full_coef=0.\n",
    "    #pdb.set_trace()\n",
    "    n_col=a.shape[1]\n",
    "    for i in range(n_col):\n",
    "        #pdb.set_trace()\n",
    "        coef, p = spearmanr(a[:,i], b[:,i])\n",
    "        full_coef +=coef\n",
    "    print(\"n_col\",float(n_col))\n",
    "    print(\"full_coef\",full_coef)\n",
    "    return full_coef/float(n_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#learn = text_classifier_learner(dbunch, AWD_LSTM, metrics=[accuracy], path=data_path,drop_mult=0.5)\n",
    "learn = text_regression_learner(dbunch, AWD_LSTM,seq_len=300, path=data_path,drop_mult=0.5).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "learn = learn.load_encoder('enc1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#export\n",
    "len(target_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.249754</td>\n",
       "      <td>0.072040</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.202688</td>\n",
       "      <td>0.054554</td>\n",
       "      <td>01:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.195247</td>\n",
       "      <td>0.051400</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.192770</td>\n",
       "      <td>0.050802</td>\n",
       "      <td>01:31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "#pdb.set_trace()\n",
    "learn.fit_one_cycle(4, moms=(0.8,0.7,0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(\"first_decoder2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai2.text.learner.TextLearner at 0x7f594f0d3c50>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load(\"first_decoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.127326</td>\n",
       "      <td>0.050574</td>\n",
       "      <td>01:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.062126</td>\n",
       "      <td>0.051281</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.054993</td>\n",
       "      <td>0.049022</td>\n",
       "      <td>01:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.051777</td>\n",
       "      <td>0.048527</td>\n",
       "      <td>01:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.049745</td>\n",
       "      <td>0.046926</td>\n",
       "      <td>01:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.049219</td>\n",
       "      <td>0.046863</td>\n",
       "      <td>01:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.049266</td>\n",
       "      <td>0.046299</td>\n",
       "      <td>01:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.048961</td>\n",
       "      <td>0.046325</td>\n",
       "      <td>01:50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.opt = learn.create_opt()\n",
    "learn.fit_one_cycle(8, slice(1e-5,1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1215, 30])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,b=learn.get_preds()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_col 30.0\n",
      "full_coef 9.442676832626423\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.31475589442088076"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spearman_corr_coef(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 1.0000, 0.5556, 0.8889, 0.8889, 1.0000, 0.8889, 1.0000, 1.0000,\n",
      "        0.8889, 1.0000, 0.8889, 0.8889, 0.8333, 1.0000, 1.0000, 0.8889, 1.0000,\n",
      "        1.0000, 0.7778])\n",
      "tensor([-0.2206,  0.6313,  0.0508,  0.7026, -0.1221,  0.3962, -0.3396,  0.1775,\n",
      "        -0.4016,  0.5615,  0.0323,  0.5073,  0.7290,  0.5127,  0.3516,  0.3015,\n",
      "         0.2112,  0.6333,  0.2668,  0.1365])\n"
     ]
    }
   ],
   "source": [
    "print(full_target[:,0])\n",
    "print(full_predict[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman_corr_coef(full_predict,full_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1260, -0.0189, -0.0305,  0.0282,  0.1493, -0.0967,  0.1312,  0.0971,\n",
       "         0.2717, -0.0007, -0.2765,  0.3127,  0.0387,  0.0097, -0.0135,  0.0609,\n",
       "        -0.3462,  0.1779,  0.3245, -0.0028,  0.0162, -0.0771, -0.0212, -0.0601,\n",
       "        -0.0312, -0.0744, -0.4155,  0.1605,  0.4971,  0.0330])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_predict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "learn.predict(L(full_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(Learner.__init__)\n",
    "def text_regression_learner(dbunch, arch, seq_len=72, config=None, pretrained=True, drop_mult=0.5,\n",
    "                            lin_ftrs=None, ps=None, **kwargs):\n",
    "    \"Create a `Learner` with a text classifier from `data` and `arch`.\"\n",
    "    vocab = _get_text_vocab(dbunch)\n",
    "    model = get_text_classifier(arch, len(vocab), len(dbunch.train_ds[0][1]), seq_len=seq_len, config=config,\n",
    "                                drop_mult=drop_mult, lin_ftrs=lin_ftrs, ps=ps)\n",
    "    meta = _model_meta[arch]\n",
    "    learn = TextLearner(dbunch, model, loss_func=MSELossFlat(), splitter=meta['split_clas'], **kwargs)\n",
    "    if pretrained:\n",
    "        if 'url' not in meta:\n",
    "            warn(\"There are no pretrained weights for that architecture yet!\")\n",
    "            return learn\n",
    "        model_path = untar_data(meta['url'], c_key='model')\n",
    "        fnames = [list(model_path.glob(f'*.{ext}'))[0] for ext in ['pth', 'pkl']]\n",
    "        learn = learn.load_pretrained(*fnames, model=learn.model[0])\n",
    "        learn.freeze()\n",
    "    return learn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}